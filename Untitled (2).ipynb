{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d74ef0b-0c34-4b71-a51b-5511678f0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89aeda6b-bf23-4242-8f01-a3ad416b5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_files = {\n",
    "    \"arxiv\": \"arxiv_test.csv\",\n",
    "    \"blogs\": \"blogs_test.csv\",\n",
    "    \"british\": \"british_test.csv\",\n",
    "    \"darkreddit\": \"darkreddit_test.csv\",\n",
    "    \"imdb\": \"imdb_test.csv\",\n",
    "    \"pan11\": \"pan11_test.csv\",\n",
    "    \"pan13\": \"pan13_test.csv\",\n",
    "    \"pan14\": \"pan14_test.csv\",\n",
    "    \"pan15\": \"pan15_test.csv\",\n",
    "    \"pan20\": \"pan20_test.csv\",\n",
    "    \"reuters\": \"reuters_test.csv\",\n",
    "    \"victorian\": \"victorian_test.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3252c26-c34c-437e-8640-e6626a9f2bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c70b5444644063b28c6726b9e113b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e90c3a8d024af28fe86a3fa6549c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/167k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62c116666e547b3a591c3748482d464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26900498c4aa4bf5b31bc6a914c9cbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaa45d9d0614c2ba318468ac0e82982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be7a38d43e34702ae7803fd8278e3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5343c0fed23645dab1865c1fbfd4506d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb532a5e01524f95b9756c65d7bcc484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.53M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61329696dd24648aa09757ce20bd023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6e34792bdd4ac6b4e2fc9641adc4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/15.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2edc2b94ff545f99b228500fa37734f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19dbb863e0d4b3bb1728c2ebd64d729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/390k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee69269169994bc8baaae923680abac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2bf3e5e1ed4de587e149ba99304c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/410k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8399abf495d7470d94d2c10821754d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4fec079ccc42eb8846d375b0eb36bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ba3392e71942d3b2151e32383b3440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951a6910eabf4fdb931e35a0c061fb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.63M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e773a920d8f4f17ac5442dcf0dc380c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac2e27580a64cd3ac787bd4425a0393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/596M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4b112083a641f6a52f7883d54d7563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d20775f15824efdb74e7fcaa19a91b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/991k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cf20ad0c814ebba921d6afa3668e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812ef2ad8d92475081a53f53c8466da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/15.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdd36e4a3014624a31c543cccd7ccf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_datasets = {name: load_dataset('swan07/authorship-verification', data_files={\"test\": file}, split='test') for name, file in test_data_files.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca8e315-ff00-45ff-906f-b9e39d08fc03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6adf4bfbb7ba465799b7b92e5c9143f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8640a64bfa493abb86717f949532d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/786k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ca9fb0e03e4007963675fa5b72d172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/89.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2abf9cd7f14bed8478d30aa718baad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/23.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684d304fe9e54d9687c80d5efc65ff0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2716b62082b44287a808e8ea8482c152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/72.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093727b474e242eeadcb4ad2b93e5957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.95M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27bb603246c4a3c9cea8427bd41e155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa0dec1216245218744477bcb8dea3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.60M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4af16b8f3345f79e3e1a44772dc449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a25768d35547bc85c5aa6b3a99b766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/10.8G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a633c241cda42b0ae7a98f242f5516a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf9042a68d64087ae9624f44c0adb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/74.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857d0974cd984a0f9cfa5d89053ae3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47be9377b694675b0244a5187b216dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebc174ffd7042ed897ad34aec7b5e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32491292f8b1402f974781faa50d214c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee6fe565ac1479285bff7df42c315bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb95de7c4d1244bdb9c757f4d02e52ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d22b5afa804d55bb8fe3c423cf7644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/15.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0a4d6ff65a47068da6052871138bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b60daecc9ff4886820f7dd01095922b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/400k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af45c21e732f427f805af3e7399c5fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.47M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345dc13a802f4c4d94289d3858b116f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.77M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15bfb6be13b4f0b9d2a27e394019206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fc6615a4f14d2891457c7ab47ec25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.01M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19adeb231b5446581baea854c032060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/15.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23df2d9c3ee04a0fa023e38f2231823a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"swan07/authorship-verification\", data_files=\"*_train.csv\", download_mode=\"force_redownload\")\n",
    "val_dataset = load_dataset(\"swan07/authorship-verification\", data_files=\"*_val.csv\", download_mode=\"force_redownload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e154985b-f4a4-4555-a5ab-c3512ab6877e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Original column name same not in the dataset. Current columns in the dataset: ['text1', 'text2', 'score']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m val_subset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mrename_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, dataset \u001b[38;5;129;01min\u001b[39;00m test_datasets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 6\u001b[0m     test_datasets[name] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/fingerprint.py:482\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:2264\u001b[0m, in \u001b[0;36mDataset.rename_column\u001b[0;34m(self, original_column_name, new_column_name, new_fingerprint)\u001b[0m\n\u001b[1;32m   2262\u001b[0m dataset \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_column_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[0;32m-> 2264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal column name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_column_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2267\u001b[0m     )\n\u001b[1;32m   2268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_column_name \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[1;32m   2269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew column name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_column_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2271\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease choose a column name which is not already in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2272\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2273\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Original column name same not in the dataset. Current columns in the dataset: ['text1', 'text2', 'score']"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "train_subset = train_dataset.rename_column(\"same\", \"score\")\n",
    "val_subset = val_dataset.rename_column(\"same\", \"score\")\n",
    "\n",
    "for name, dataset in test_datasets.items():\n",
    "    test_datasets[name] = dataset.rename_column(\"same\", \"score\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf8d00-4abf-4f0d-8fde-9af01637bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #subset\n",
    "# data_files_subset = {\"train\": \"arxiv_train.csv\", \"eval\": \"arxiv_val.csv\"}\n",
    "# train_subsets = load_dataset(\"swan07/authorship-verification\", data_files=data_files_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d78ccdc-12b3-4497-9c9b-19ffb4e2550c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_subsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubset.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mtrain_subsets\u001b[49m, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_subsets' is not defined"
     ]
    }
   ],
   "source": [
    "with open('subset.pkl', 'wb') as f:\n",
    "    pickle.dump(train_subsets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca30c32-c65c-4b25-a511-743d860cb0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pkl', 'wb') as f:\n",
    "    pickle.dump(train_subset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a5adbd69-ba04-486a-bc0b-1624695b7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c71ce2a4-2ce7-4aac-a694-adab8819fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.pkl', 'wb') as f:\n",
    "    pickle.dump(test_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8c300a37-7845-4331-8442-c71178587fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77421327-fcf8-4635-a33f-a29b94754641",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val.pkl', 'wb') as f:\n",
    "    pickle.dump(val_subset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb409354-b811-4299-8d18-35ae67700e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_subset = train_subsets['train']\n",
    "# test_subset = test_datasets['arxiv']\n",
    "# val_subset = train_subsets['eval']\n",
    "\n",
    "train_subset = train_dataset\n",
    "test_subset = test_datasets\n",
    "val_subset = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a2836-aba7-419d-8c9e-820e84b7e9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "84f53a4b-b024-4e88-baeb-cf0660abe244",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train_subset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "19c5a4e9-22c0-4f3b-bef3-dc1af02fbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subset = val_subset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee12bf45-a8bc-4326-a09a-f801ce72cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_subset is a dict, not a ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ee9673fa-3f09-4575-bcb3-74b41315c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273ead4-c036-42fc-85cc-dd4b86bda944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b66f227f-0fc1-48a7-8d7e-323a4122f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128  # Replace with your model's max sequence length\n",
    "def chunk_text(text, max_length):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+max_length]) for i in range(0, len(words), max_length)]\n",
    "\n",
    "def create_chunked_pairs(text1, text2, max_length):\n",
    "    chunks1 = chunk_text(text1, max_length)\n",
    "    chunks2 = chunk_text(text2, max_length)\n",
    "    max_chunks = min(len(chunks1), len(chunks2))\n",
    "    \n",
    "    chunked_pairs = []\n",
    "    for i in range(max_chunks):\n",
    "        chunk1 = chunks1[i] if i < len(chunks1) else \"\"\n",
    "        chunk2 = chunks2[i] if i < len(chunks2) else \"\"\n",
    "        chunked_pairs.append((chunk1, chunk2))\n",
    "    \n",
    "    return chunked_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef756ab8-898c-4527-b877-249727517f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_train_examples = []\n",
    "num = 0\n",
    "\n",
    "for example in train_subset:\n",
    "    if num > 2:\n",
    "        break\n",
    "    num +=1\n",
    "    text1 = example['text1']\n",
    "    text2 = example['text2']\n",
    "    score = example['score']\n",
    "\n",
    "    chunked_pairs = create_chunked_pairs(text1, text2, max_seq_length)\n",
    "    for chunk1, chunk2 in chunked_pairs:\n",
    "        chunked_train_examples.append(InputExample(texts=[chunk1, chunk2], label=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "05e22e10-e1de-4255-86df-dde2ff62b94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<sentence_transformers.readers.InputExample.InputExample at 0x7fc80c53d660>,\n",
       " <sentence_transformers.readers.InputExample.InputExample at 0x7fc80c53d810>,\n",
       " <sentence_transformers.readers.InputExample.InputExample at 0x7fc80c53cca0>,\n",
       " <sentence_transformers.readers.InputExample.InputExample at 0x7fc80c53eb90>]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_train_examples[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8caed3ea-386d-49bf-a6c5-487c730cea45",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'texts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m chunked_train_dataset \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m train_subset:\n\u001b[0;32m----> 3\u001b[0m     chunked_pairs \u001b[38;5;241m=\u001b[39m create_chunked_pairs(\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexts\u001b[49m[\u001b[38;5;241m0\u001b[39m], example\u001b[38;5;241m.\u001b[39mtexts[\u001b[38;5;241m1\u001b[39m], max_seq_length)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk1, chunk2 \u001b[38;5;129;01min\u001b[39;00m chunked_pairs:\n\u001b[1;32m      5\u001b[0m         chunked_train_dataset\u001b[38;5;241m.\u001b[39mappend(InputExample(texts\u001b[38;5;241m=\u001b[39m[chunk1, chunk2], label\u001b[38;5;241m=\u001b[39mexample\u001b[38;5;241m.\u001b[39mlabel))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'texts'"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    texts1 = [example.texts[0] for example in batch]\n",
    "    texts2 = [example.texts[1] for example in batch]\n",
    "    labels = [example.label for example in batch]\n",
    "    \n",
    "    # Tokenize and pad the texts\n",
    "    inputs1 = tokenizer(texts1, padding=True, truncation=True, max_length=max_seq_length, return_tensors=\"pt\")\n",
    "    inputs2 = tokenizer(texts2, padding=True, truncation=True, max_length=max_seq_length, return_tensors=\"pt\")\n",
    "    \n",
    "    return {\n",
    "        'input_ids1': inputs1['input_ids'],\n",
    "        'attention_mask1': inputs1['attention_mask'],\n",
    "        'input_ids2': inputs2['input_ids'],\n",
    "        'attention_mask2': inputs2['attention_mask'],\n",
    "        'labels': torch.tensor(labels)\n",
    "    }\n",
    "\n",
    "train_dataloader = DataLoader(chunked_train_examples, shuffle=True, batch_size=16, collate_fn=collate_fn)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# Training\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    warmup_steps=100,\n",
    "    show_progress_bar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094533fd-09e8-4a09-91da-60deebb71d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb63a2c0-8e4f-4a6b-8112-84734919f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import ContrastiveLoss\n",
    "\n",
    "loss = ContrastiveLoss(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e472854-da3e-439b-b149-b7539853d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "# Load the model\n",
    "model1 = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "# Define the dataloader\n",
    "\n",
    "# Define the loss\n",
    "train_loss = ContrastiveLoss(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fabc0fb8-e48d-4d9a-94a4-3f857156d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chunk(text, max_length, tokenizer):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) <= max_length:\n",
    "        return tokenizer.convert_tokens_to_string(tokens)\n",
    "    \n",
    "    # Randomly select a chunk\n",
    "    start_index = random.randint(0, len(tokens) - max_length)\n",
    "    chunk = tokens[start_index:start_index + max_length]\n",
    "    return tokenizer.convert_tokens_to_string(chunk)\n",
    "\n",
    "def truncate_sequences(text1, text2, max_length, tokenizer):\n",
    "    text1_chunk = random_chunk(text1, max_length // 2, tokenizer)\n",
    "    text2_chunk = random_chunk(text2, max_length // 2, tokenizer)\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text1_chunk, text2_chunk,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    return encoded_dict['input_ids'], encoded_dict['attention_mask']\n",
    "\n",
    "# Apply truncation to datasets\n",
    "def process_dataset(dataset, max_length):\n",
    "    processed_data = {\n",
    "        'text1': [],\n",
    "        'text2': [],\n",
    "        'input_ids': [],\n",
    "        'attention_mask': [],\n",
    "        'score': []\n",
    "    }\n",
    "    for i in range(len(dataset)):\n",
    "        row = dataset[i]\n",
    "        input_ids, attention_mask = truncate_sequences(row['text1'], row['text2'], max_length, tokenizer)\n",
    "        processed_data['text1'].append(row['text1'])\n",
    "        processed_data['text2'].append(row['text2'])\n",
    "        processed_data['input_ids'].append(input_ids)\n",
    "        processed_data['attention_mask'].append(attention_mask)\n",
    "        processed_data['score'].append(row['score'])\n",
    "    return processed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b02b802f-1115-4153-adf2-98938b401e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the datasets\n",
    "train_dataset1 = train_subset['train']\n",
    "eval_dataset1 = val_subset['train']\n",
    "test_dataset1 = test_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4b598d9-2fe4-47f7-ae76-727f45e60a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define max length for the model (e.g., 256 tokens)\n",
    "max_length = 256\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b8ad1-b833-4356-aede-aec7469cca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d05df91b-7b1f-4822-bcb6-5ebdf8bb1b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, dataset \u001b[38;5;129;01min\u001b[39;00m test_dataset1\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     test_dataset1[name] \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(name)\n",
      "Cell \u001b[0;32mIn[73], line 34\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[0;34m(dataset, max_length)\u001b[0m\n\u001b[1;32m     26\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext1\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext2\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m     32\u001b[0m }\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m---> 34\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     35\u001b[0m     input_ids, attention_mask \u001b[38;5;241m=\u001b[39m truncate_sequences(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext1\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext2\u001b[39m\u001b[38;5;124m'\u001b[39m], max_length, tokenizer)\n\u001b[1;32m     36\u001b[0m     processed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for name, dataset in test_dataset1.items():\n",
    "    test_dataset1[name] = process_dataset(dataset, max_length)\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5448a3c-5da6-47aa-9f30-4ecadd076937",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_dataset1 = process_dataset(eval_dataset1, max_length)\n",
    "\n",
    "# Process datasets\n",
    "train_dataset1 = process_dataset(train_dataset1, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffaa330-974c-4e01-836c-bf9f4e7791d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the training data\n",
    "train_examples = [InputExample(texts=[row['text1'], row['text2']], label=row['score']) for row in train_dataset]\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e7ce9-dfd1-416d-a5d5-17f353111d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args1 = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"models/all-MiniLM-L12-v2\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,\n",
    "    logging_dir='./logs', \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"all-MiniLM-L12-v2\",\n",
    "    resume_from_checkpoint=True,  # Add this line to resume from the last checkpoint\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6f97b-529e-4c98-a8e0-29a72b5c2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the trainer\n",
    "trainer1 = SentenceTransformerTrainer(\n",
    "    model=model1,\n",
    "    args=training_args1,\n",
    "    train_dataset=train_dataloader,\n",
    "    eval_dataset=eval_dataset1,\n",
    "    loss=train_loss\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer1.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142ba42-d78d-4dfc-8476-b26775ccca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_evaluator1 = BinaryClassificationEvaluator(\n",
    "    sentences1=test_dataset1[\"text1\"],\n",
    "    sentences2=test_dataset1[\"text2\"],\n",
    "    labels=test_dataset1[\"score\"],\n",
    "    name=\"v2\",\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "test_evaluator(model1)\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained(\"models/all-MiniLM-L12-v2/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "da08f45d-e7eb-4932-b3b7-7959239be50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"models/minilm\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,\n",
    "    logging_dir='./logs', \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"minilm-contrastive\",\n",
    "    resume_from_checkpoint=True,  # Add this line to resume from the last checkpoint\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92ccbef7-61cf-4570-ae22-87d5aff33c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import ContrastiveLoss\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# 3. Load a dataset to finetune on\n",
    "train_dataset = train_subset\n",
    "eval_dataset = val_subset\n",
    "test_dataset = test_subset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eacb5e-777f-4b2f-a68b-c2a80e687247",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_evaluator = BinaryClassificationEvaluator(\n",
    "    sentences1=eval_dataset['train'][\"text1\"],\n",
    "    sentences2=eval_dataset['train'][\"text2\"],\n",
    "    labels=eval_dataset['train'][\"score\"],\n",
    "    name=\"all-nli-dev\",\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "dev_evaluator(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7d9ebd16-31b8-41a1-b78d-24a94b61e527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text1', 'text2', 'same'],\n",
       "        num_rows: 30781\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2122b6a9-044d-4db3-baa5-5792049f751c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SentenceTransformer:\n\tUnexpected key(s) in state_dict: \"0.auto_model.encoder.layer.6.attention.self.query.weight\", \"0.auto_model.encoder.layer.6.attention.self.query.bias\", \"0.auto_model.encoder.layer.6.attention.self.key.weight\", \"0.auto_model.encoder.layer.6.attention.self.key.bias\", \"0.auto_model.encoder.layer.6.attention.self.value.weight\", \"0.auto_model.encoder.layer.6.attention.self.value.bias\", \"0.auto_model.encoder.layer.6.attention.output.dense.weight\", \"0.auto_model.encoder.layer.6.attention.output.dense.bias\", \"0.auto_model.encoder.layer.6.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.6.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.6.intermediate.dense.weight\", \"0.auto_model.encoder.layer.6.intermediate.dense.bias\", \"0.auto_model.encoder.layer.6.output.dense.weight\", \"0.auto_model.encoder.layer.6.output.dense.bias\", \"0.auto_model.encoder.layer.6.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.6.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.7.attention.self.query.weight\", \"0.auto_model.encoder.layer.7.attention.self.query.bias\", \"0.auto_model.encoder.layer.7.attention.self.key.weight\", \"0.auto_model.encoder.layer.7.attention.self.key.bias\", \"0.auto_model.encoder.layer.7.attention.self.value.weight\", \"0.auto_model.encoder.layer.7.attention.self.value.bias\", \"0.auto_model.encoder.layer.7.attention.output.dense.weight\", \"0.auto_model.encoder.layer.7.attention.output.dense.bias\", \"0.auto_model.encoder.layer.7.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.7.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.7.intermediate.dense.weight\", \"0.auto_model.encoder.layer.7.intermediate.dense.bias\", \"0.auto_model.encoder.layer.7.output.dense.weight\", \"0.auto_model.encoder.layer.7.output.dense.bias\", \"0.auto_model.encoder.layer.7.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.7.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.8.attention.self.query.weight\", \"0.auto_model.encoder.layer.8.attention.self.query.bias\", \"0.auto_model.encoder.layer.8.attention.self.key.weight\", \"0.auto_model.encoder.layer.8.attention.self.key.bias\", \"0.auto_model.encoder.layer.8.attention.self.value.weight\", \"0.auto_model.encoder.layer.8.attention.self.value.bias\", \"0.auto_model.encoder.layer.8.attention.output.dense.weight\", \"0.auto_model.encoder.layer.8.attention.output.dense.bias\", \"0.auto_model.encoder.layer.8.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.8.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.8.intermediate.dense.weight\", \"0.auto_model.encoder.layer.8.intermediate.dense.bias\", \"0.auto_model.encoder.layer.8.output.dense.weight\", \"0.auto_model.encoder.layer.8.output.dense.bias\", \"0.auto_model.encoder.layer.8.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.8.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.9.attention.self.query.weight\", \"0.auto_model.encoder.layer.9.attention.self.query.bias\", \"0.auto_model.encoder.layer.9.attention.self.key.weight\", \"0.auto_model.encoder.layer.9.attention.self.key.bias\", \"0.auto_model.encoder.layer.9.attention.self.value.weight\", \"0.auto_model.encoder.layer.9.attention.self.value.bias\", \"0.auto_model.encoder.layer.9.attention.output.dense.weight\", \"0.auto_model.encoder.layer.9.attention.output.dense.bias\", \"0.auto_model.encoder.layer.9.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.9.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.9.intermediate.dense.weight\", \"0.auto_model.encoder.layer.9.intermediate.dense.bias\", \"0.auto_model.encoder.layer.9.output.dense.weight\", \"0.auto_model.encoder.layer.9.output.dense.bias\", \"0.auto_model.encoder.layer.9.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.9.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.10.attention.self.query.weight\", \"0.auto_model.encoder.layer.10.attention.self.query.bias\", \"0.auto_model.encoder.layer.10.attention.self.key.weight\", \"0.auto_model.encoder.layer.10.attention.self.key.bias\", \"0.auto_model.encoder.layer.10.attention.self.value.weight\", \"0.auto_model.encoder.layer.10.attention.self.value.bias\", \"0.auto_model.encoder.layer.10.attention.output.dense.weight\", \"0.auto_model.encoder.layer.10.attention.output.dense.bias\", \"0.auto_model.encoder.layer.10.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.10.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.10.intermediate.dense.weight\", \"0.auto_model.encoder.layer.10.intermediate.dense.bias\", \"0.auto_model.encoder.layer.10.output.dense.weight\", \"0.auto_model.encoder.layer.10.output.dense.bias\", \"0.auto_model.encoder.layer.10.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.10.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.11.attention.self.query.weight\", \"0.auto_model.encoder.layer.11.attention.self.query.bias\", \"0.auto_model.encoder.layer.11.attention.self.key.weight\", \"0.auto_model.encoder.layer.11.attention.self.key.bias\", \"0.auto_model.encoder.layer.11.attention.self.value.weight\", \"0.auto_model.encoder.layer.11.attention.self.value.bias\", \"0.auto_model.encoder.layer.11.attention.output.dense.weight\", \"0.auto_model.encoder.layer.11.attention.output.dense.bias\", \"0.auto_model.encoder.layer.11.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.11.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.11.intermediate.dense.weight\", \"0.auto_model.encoder.layer.11.intermediate.dense.bias\", \"0.auto_model.encoder.layer.11.output.dense.weight\", \"0.auto_model.encoder.layer.11.output.dense.bias\", \"0.auto_model.encoder.layer.11.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.11.output.LayerNorm.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 7. Create a trainer & train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mdev_evaluator,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1857\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resume_from_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_enabled:\n\u001b[0;32m-> 1857\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;66;03m# In case of repeating the find_executable_batch_size, set `self._train_batch_size` properly\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m     state \u001b[38;5;241m=\u001b[39m TrainerState\u001b[38;5;241m.\u001b[39mload_from_json(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(resume_from_checkpoint, TRAINER_STATE_NAME))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/trainer.py:739\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer._load_from_checkpoint\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m    738\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(checkpoint_path)\n\u001b[0;32m--> 739\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SentenceTransformer:\n\tUnexpected key(s) in state_dict: \"0.auto_model.encoder.layer.6.attention.self.query.weight\", \"0.auto_model.encoder.layer.6.attention.self.query.bias\", \"0.auto_model.encoder.layer.6.attention.self.key.weight\", \"0.auto_model.encoder.layer.6.attention.self.key.bias\", \"0.auto_model.encoder.layer.6.attention.self.value.weight\", \"0.auto_model.encoder.layer.6.attention.self.value.bias\", \"0.auto_model.encoder.layer.6.attention.output.dense.weight\", \"0.auto_model.encoder.layer.6.attention.output.dense.bias\", \"0.auto_model.encoder.layer.6.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.6.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.6.intermediate.dense.weight\", \"0.auto_model.encoder.layer.6.intermediate.dense.bias\", \"0.auto_model.encoder.layer.6.output.dense.weight\", \"0.auto_model.encoder.layer.6.output.dense.bias\", \"0.auto_model.encoder.layer.6.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.6.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.7.attention.self.query.weight\", \"0.auto_model.encoder.layer.7.attention.self.query.bias\", \"0.auto_model.encoder.layer.7.attention.self.key.weight\", \"0.auto_model.encoder.layer.7.attention.self.key.bias\", \"0.auto_model.encoder.layer.7.attention.self.value.weight\", \"0.auto_model.encoder.layer.7.attention.self.value.bias\", \"0.auto_model.encoder.layer.7.attention.output.dense.weight\", \"0.auto_model.encoder.layer.7.attention.output.dense.bias\", \"0.auto_model.encoder.layer.7.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.7.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.7.intermediate.dense.weight\", \"0.auto_model.encoder.layer.7.intermediate.dense.bias\", \"0.auto_model.encoder.layer.7.output.dense.weight\", \"0.auto_model.encoder.layer.7.output.dense.bias\", \"0.auto_model.encoder.layer.7.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.7.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.8.attention.self.query.weight\", \"0.auto_model.encoder.layer.8.attention.self.query.bias\", \"0.auto_model.encoder.layer.8.attention.self.key.weight\", \"0.auto_model.encoder.layer.8.attention.self.key.bias\", \"0.auto_model.encoder.layer.8.attention.self.value.weight\", \"0.auto_model.encoder.layer.8.attention.self.value.bias\", \"0.auto_model.encoder.layer.8.attention.output.dense.weight\", \"0.auto_model.encoder.layer.8.attention.output.dense.bias\", \"0.auto_model.encoder.layer.8.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.8.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.8.intermediate.dense.weight\", \"0.auto_model.encoder.layer.8.intermediate.dense.bias\", \"0.auto_model.encoder.layer.8.output.dense.weight\", \"0.auto_model.encoder.layer.8.output.dense.bias\", \"0.auto_model.encoder.layer.8.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.8.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.9.attention.self.query.weight\", \"0.auto_model.encoder.layer.9.attention.self.query.bias\", \"0.auto_model.encoder.layer.9.attention.self.key.weight\", \"0.auto_model.encoder.layer.9.attention.self.key.bias\", \"0.auto_model.encoder.layer.9.attention.self.value.weight\", \"0.auto_model.encoder.layer.9.attention.self.value.bias\", \"0.auto_model.encoder.layer.9.attention.output.dense.weight\", \"0.auto_model.encoder.layer.9.attention.output.dense.bias\", \"0.auto_model.encoder.layer.9.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.9.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.9.intermediate.dense.weight\", \"0.auto_model.encoder.layer.9.intermediate.dense.bias\", \"0.auto_model.encoder.layer.9.output.dense.weight\", \"0.auto_model.encoder.layer.9.output.dense.bias\", \"0.auto_model.encoder.layer.9.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.9.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.10.attention.self.query.weight\", \"0.auto_model.encoder.layer.10.attention.self.query.bias\", \"0.auto_model.encoder.layer.10.attention.self.key.weight\", \"0.auto_model.encoder.layer.10.attention.self.key.bias\", \"0.auto_model.encoder.layer.10.attention.self.value.weight\", \"0.auto_model.encoder.layer.10.attention.self.value.bias\", \"0.auto_model.encoder.layer.10.attention.output.dense.weight\", \"0.auto_model.encoder.layer.10.attention.output.dense.bias\", \"0.auto_model.encoder.layer.10.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.10.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.10.intermediate.dense.weight\", \"0.auto_model.encoder.layer.10.intermediate.dense.bias\", \"0.auto_model.encoder.layer.10.output.dense.weight\", \"0.auto_model.encoder.layer.10.output.dense.bias\", \"0.auto_model.encoder.layer.10.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.10.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.11.attention.self.query.weight\", \"0.auto_model.encoder.layer.11.attention.self.query.bias\", \"0.auto_model.encoder.layer.11.attention.self.key.weight\", \"0.auto_model.encoder.layer.11.attention.self.key.bias\", \"0.auto_model.encoder.layer.11.attention.self.value.weight\", \"0.auto_model.encoder.layer.11.attention.self.value.bias\", \"0.auto_model.encoder.layer.11.attention.output.dense.weight\", \"0.auto_model.encoder.layer.11.attention.output.dense.bias\", \"0.auto_model.encoder.layer.11.attention.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.11.attention.output.LayerNorm.bias\", \"0.auto_model.encoder.layer.11.intermediate.dense.weight\", \"0.auto_model.encoder.layer.11.intermediate.dense.bias\", \"0.auto_model.encoder.layer.11.output.dense.weight\", \"0.auto_model.encoder.layer.11.output.dense.bias\", \"0.auto_model.encoder.layer.11.output.LayerNorm.weight\", \"0.auto_model.encoder.layer.11.output.LayerNorm.bias\". "
     ]
    }
   ],
   "source": [
    "# 7. Create a trainer & train\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train(resume_from_checkpoint=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3e9f3ed-0d6c-4293-a306-87c4aafc666f",
   "metadata": {},
   "source": [
    "for name, test_dataset in test_datasets.items():\n",
    "    test_evaluator = BinaryClassificationEvaluator(\n",
    "        sentences1=test_dataset[\"text1\"],\n",
    "        sentences2=test_dataset[\"text2\"],\n",
    "        labels=test_dataset[\"score\"],\n",
    "        name=f\"{name}-test\",\n",
    "        show_progress_bar=True,\n",
    "    )\n",
    "    evaluation_result = test_evaluator(model)\n",
    "    print(f\"Evaluation result for {name}: {evaluation_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc617be6-5c61-4dbe-8915-de7606433758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25303e1f17c941c4b658d2e27834178c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'all-nli-test_cosine_accuracy': 0.7830188679245284,\n",
       " 'all-nli-test_cosine_accuracy_threshold': 0.8684796094894409,\n",
       " 'all-nli-test_cosine_f1': 0.8226950354609929,\n",
       " 'all-nli-test_cosine_f1_threshold': 0.7826629877090454,\n",
       " 'all-nli-test_cosine_precision': 0.7160493827160493,\n",
       " 'all-nli-test_cosine_recall': 0.9666666666666667,\n",
       " 'all-nli-test_cosine_ap': 0.909027897659408,\n",
       " 'all-nli-test_dot_accuracy': 0.7830188679245284,\n",
       " 'all-nli-test_dot_accuracy_threshold': 0.8684795498847961,\n",
       " 'all-nli-test_dot_f1': 0.8226950354609929,\n",
       " 'all-nli-test_dot_f1_threshold': 0.7826629877090454,\n",
       " 'all-nli-test_dot_precision': 0.7160493827160493,\n",
       " 'all-nli-test_dot_recall': 0.9666666666666667,\n",
       " 'all-nli-test_dot_ap': 0.909027897659408,\n",
       " 'all-nli-test_manhattan_accuracy': 0.7735849056603774,\n",
       " 'all-nli-test_manhattan_accuracy_threshold': 8.151639938354492,\n",
       " 'all-nli-test_manhattan_f1': 0.8088235294117647,\n",
       " 'all-nli-test_manhattan_f1_threshold': 10.046613693237305,\n",
       " 'all-nli-test_manhattan_precision': 0.7236842105263158,\n",
       " 'all-nli-test_manhattan_recall': 0.9166666666666666,\n",
       " 'all-nli-test_manhattan_ap': 0.9044190107189773,\n",
       " 'all-nli-test_euclidean_accuracy': 0.7830188679245284,\n",
       " 'all-nli-test_euclidean_accuracy_threshold': 0.5128726959228516,\n",
       " 'all-nli-test_euclidean_f1': 0.8226950354609929,\n",
       " 'all-nli-test_euclidean_f1_threshold': 0.6592979431152344,\n",
       " 'all-nli-test_euclidean_precision': 0.7160493827160493,\n",
       " 'all-nli-test_euclidean_recall': 0.9666666666666667,\n",
       " 'all-nli-test_euclidean_ap': 0.909027897659408,\n",
       " 'all-nli-test_max_accuracy': 0.7830188679245284,\n",
       " 'all-nli-test_max_accuracy_threshold': 8.151639938354492,\n",
       " 'all-nli-test_max_f1': 0.8226950354609929,\n",
       " 'all-nli-test_max_f1_threshold': 10.046613693237305,\n",
       " 'all-nli-test_max_precision': 0.7236842105263158,\n",
       " 'all-nli-test_max_recall': 0.9666666666666667,\n",
       " 'all-nli-test_max_ap': 0.909027897659408}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# (Optional) Evaluate the trained model on the test set, after training completes\n",
    "test_evaluator = BinaryClassificationEvaluator(\n",
    "    sentences1=test_dataset[\"text1\"],\n",
    "    sentences2=test_dataset[\"text2\"],\n",
    "    labels=test_dataset[\"score\"],\n",
    "    name=\"all-nli-test\",\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "test_evaluator(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc4072-fbd8-4022-b15a-fe75a5a75834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8. Save the trained model\n",
    "model.save_pretrained(\"models/all-MiniLM-L12-v2t/final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
