{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca841c3b-60c3-4f1a-89d6-b3de6030ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6302606b-2746-491a-870a-195e43db84d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_files = {\n",
    "    \"arxiv\": \"arxiv_test.csv\",\n",
    "    \"blogs\": \"blogs_test.csv\",\n",
    "    \"british\": \"british_test.csv\",\n",
    "    \"darkreddit\": \"darkreddit_test.csv\",\n",
    "    \"imdb\": \"imdb_test.csv\",\n",
    "    \"pan11\": \"pan11_test.csv\",\n",
    "    \"pan13\": \"pan13_test.csv\",\n",
    "    \"pan14\": \"pan14_test.csv\",\n",
    "    \"pan15\": \"pan15_test.csv\",\n",
    "    \"pan20\": \"pan20_test.csv\",\n",
    "    \"reuters\": \"reuters_test.csv\",\n",
    "    \"victorian\": \"victorian_test.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b8b2c-f941-4181-8ced-46be542c43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = {name: load_dataset('swan07/authorship-verification', data_files={\"test\": file}, split='test') for name, file in test_data_files.items()}\n",
    "train_dataset = load_dataset(\"swan07/authorship-verification\", data_files=\"*_train.csv\", download_mode=\"force_redownload\")\n",
    "val_dataset = load_dataset(\"swan07/authorship-verification\", data_files=\"*_val.csv\", download_mode=\"force_redownload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58c13d5-e1b6-4c2c-ac3b-b4208986acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train_dataset\n",
    "test_subset = test_datasets\n",
    "val_subset = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0c70b4f-9917-43d4-b340-99efb8537464",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Original column name same not in the dataset. Current columns in the dataset: ['text1', 'text2', 'score']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m val_subset \u001b[38;5;241m=\u001b[39m val_subset\u001b[38;5;241m.\u001b[39mrename_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, dataset \u001b[38;5;129;01min\u001b[39;00m test_subset\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 5\u001b[0m     test_subset[name] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/fingerprint.py:482\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:2264\u001b[0m, in \u001b[0;36mDataset.rename_column\u001b[0;34m(self, original_column_name, new_column_name, new_fingerprint)\u001b[0m\n\u001b[1;32m   2262\u001b[0m dataset \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_column_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[0;32m-> 2264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal column name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_column_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2267\u001b[0m     )\n\u001b[1;32m   2268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_column_name \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[1;32m   2269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew column name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_column_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2271\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease choose a column name which is not already in the dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2272\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2273\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Original column name same not in the dataset. Current columns in the dataset: ['text1', 'text2', 'score']"
     ]
    }
   ],
   "source": [
    "train_subset = train_subset.rename_column(\"same\", \"score\")\n",
    "val_subset = val_subset.rename_column(\"same\", \"score\")\n",
    "\n",
    "for name, dataset in test_subset.items():\n",
    "    test_subset[name] = dataset.rename_column(\"same\", \"score\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d742a3c8-88f8-4434-be96-61b852bcd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train_subset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c3e36af-a10c-447a-b0da-f17f458f3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subset = val_subset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a13584be-88db-4519-9938-c42cc749681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"minilm\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,\n",
    "    logging_dir='./logs', \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    run_name=\"minilm-new\",\n",
    "    resume_from_checkpoint=True,  # Add this line to resume from the last checkpoint\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f40127e5-fcde-4036-9e79-07cf14b7b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers.losses import ContrastiveLoss\n",
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16ce3951-807e-4f27-9b7a-3a54c78eda7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96b9f49c-6781-4758-93d3-2dd6945fb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import ContrastiveLoss\n",
    "\n",
    "loss = ContrastiveLoss(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447b929-a76d-4e83-ae1e-a26ce10c8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_evaluator = BinaryClassificationEvaluator(\n",
    "    sentences1=val_subset[\"text1\"],\n",
    "    sentences2=val_subset[\"text2\"],\n",
    "    labels=val_subset[\"score\"],\n",
    "    name=\"all-nli-dev\",\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "dev_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ac0e0-ce8d-4830-b4f4-a049dbf070eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create a trainer & train\n",
    "#epoch 2\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=val_subset,\n",
    "    loss=loss,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a18a9620-2037-4a7a-bfa4-669604451da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arxiv': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 106\n",
       " }),\n",
       " 'blogs': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 8840\n",
       " }),\n",
       " 'british': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 173\n",
       " }),\n",
       " 'darkreddit': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 412\n",
       " }),\n",
       " 'imdb': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 4648\n",
       " }),\n",
       " 'pan11': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 698\n",
       " }),\n",
       " 'pan13': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 18\n",
       " }),\n",
       " 'pan14': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 400\n",
       " }),\n",
       " 'pan15': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 200\n",
       " }),\n",
       " 'pan20': Dataset({\n",
       "     features: ['score', 'text1', 'text2'],\n",
       "     num_rows: 13704\n",
       " }),\n",
       " 'reuters': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 181\n",
       " }),\n",
       " 'victorian': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 1608\n",
       " })}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d76fe2c-d357-485b-b133-780baf8ec6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b122b5b8a1a4e8d87b9bfca1d40e388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for arxiv: {'arxiv-test_cosine_accuracy': 0.8301886792452831, 'arxiv-test_cosine_accuracy_threshold': 0.6947098970413208, 'arxiv-test_cosine_f1': 0.859375, 'arxiv-test_cosine_f1_threshold': 0.6901332139968872, 'arxiv-test_cosine_precision': 0.8088235294117647, 'arxiv-test_cosine_recall': 0.9166666666666666, 'arxiv-test_cosine_ap': 0.9059438222711578, 'arxiv-test_dot_accuracy': 0.8301886792452831, 'arxiv-test_dot_accuracy_threshold': 0.6947098970413208, 'arxiv-test_dot_f1': 0.859375, 'arxiv-test_dot_f1_threshold': 0.6901331543922424, 'arxiv-test_dot_precision': 0.8088235294117647, 'arxiv-test_dot_recall': 0.9166666666666666, 'arxiv-test_dot_ap': 0.9059438222711578, 'arxiv-test_manhattan_accuracy': 0.8301886792452831, 'arxiv-test_manhattan_accuracy_threshold': 11.346436500549316, 'arxiv-test_manhattan_f1': 0.8524590163934426, 'arxiv-test_manhattan_f1_threshold': 11.891170501708984, 'arxiv-test_manhattan_precision': 0.8387096774193549, 'arxiv-test_manhattan_recall': 0.8666666666666667, 'arxiv-test_manhattan_ap': 0.9045771892443434, 'arxiv-test_euclidean_accuracy': 0.8301886792452831, 'arxiv-test_euclidean_accuracy_threshold': 0.781387448310852, 'arxiv-test_euclidean_f1': 0.859375, 'arxiv-test_euclidean_f1_threshold': 0.7872311472892761, 'arxiv-test_euclidean_precision': 0.8088235294117647, 'arxiv-test_euclidean_recall': 0.9166666666666666, 'arxiv-test_euclidean_ap': 0.9059438222711578, 'arxiv-test_max_accuracy': 0.8301886792452831, 'arxiv-test_max_accuracy_threshold': 11.346436500549316, 'arxiv-test_max_f1': 0.859375, 'arxiv-test_max_f1_threshold': 11.891170501708984, 'arxiv-test_max_precision': 0.8387096774193549, 'arxiv-test_max_recall': 0.9166666666666666, 'arxiv-test_max_ap': 0.9059438222711578}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99795b3b51a44639b38a8bb2c56674b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for blogs: {'blogs-test_cosine_accuracy': 0.6916289592760181, 'blogs-test_cosine_accuracy_threshold': 0.7527225613594055, 'blogs-test_cosine_f1': 0.713355944632872, 'blogs-test_cosine_f1_threshold': 0.6621318459510803, 'blogs-test_cosine_precision': 0.5979714153988013, 'blogs-test_cosine_recall': 0.8839164016356201, 'blogs-test_cosine_ap': 0.7724042084291309, 'blogs-test_dot_accuracy': 0.6916289592760181, 'blogs-test_dot_accuracy_threshold': 0.7527225613594055, 'blogs-test_dot_f1': 0.713355944632872, 'blogs-test_dot_f1_threshold': 0.6621319055557251, 'blogs-test_dot_precision': 0.5979714153988013, 'blogs-test_dot_recall': 0.8839164016356201, 'blogs-test_dot_ap': 0.7724044139768769, 'blogs-test_manhattan_accuracy': 0.6921945701357466, 'blogs-test_manhattan_accuracy_threshold': 11.203267097473145, 'blogs-test_manhattan_f1': 0.7121798415330755, 'blogs-test_manhattan_f1_threshold': 12.767942428588867, 'blogs-test_manhattan_precision': 0.5990390576565406, 'blogs-test_manhattan_recall': 0.8780099954566106, 'blogs-test_manhattan_ap': 0.7712620822637055, 'blogs-test_euclidean_accuracy': 0.6916289592760181, 'blogs-test_euclidean_accuracy_threshold': 0.7032459378242493, 'blogs-test_euclidean_f1': 0.713355944632872, 'blogs-test_euclidean_f1_threshold': 0.8220318555831909, 'blogs-test_euclidean_precision': 0.5979714153988013, 'blogs-test_euclidean_recall': 0.8839164016356201, 'blogs-test_euclidean_ap': 0.772404206046575, 'blogs-test_max_accuracy': 0.6921945701357466, 'blogs-test_max_accuracy_threshold': 11.203267097473145, 'blogs-test_max_f1': 0.713355944632872, 'blogs-test_max_f1_threshold': 12.767942428588867, 'blogs-test_max_precision': 0.5990390576565406, 'blogs-test_max_recall': 0.8839164016356201, 'blogs-test_max_ap': 0.7724044139768769}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ff97abe06f4aae9779c54521cff246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for british: {'british-test_cosine_accuracy': 0.7687861271676301, 'british-test_cosine_accuracy_threshold': 0.7162458300590515, 'british-test_cosine_f1': 0.8053097345132744, 'british-test_cosine_f1_threshold': 0.6518328189849854, 'british-test_cosine_precision': 0.7109375, 'british-test_cosine_recall': 0.9285714285714286, 'british-test_cosine_ap': 0.8657974477850441, 'british-test_dot_accuracy': 0.7687861271676301, 'british-test_dot_accuracy_threshold': 0.7162458896636963, 'british-test_dot_f1': 0.8053097345132744, 'british-test_dot_f1_threshold': 0.6518328785896301, 'british-test_dot_precision': 0.7109375, 'british-test_dot_recall': 0.9285714285714286, 'british-test_dot_ap': 0.8657974477850441, 'british-test_manhattan_accuracy': 0.7572254335260116, 'british-test_manhattan_accuracy_threshold': 11.92885971069336, 'british-test_manhattan_f1': 0.8071748878923766, 'british-test_manhattan_f1_threshold': 12.846293449401855, 'british-test_manhattan_precision': 0.72, 'british-test_manhattan_recall': 0.9183673469387755, 'british-test_manhattan_ap': 0.8596491162208274, 'british-test_euclidean_accuracy': 0.7687861271676301, 'british-test_euclidean_accuracy_threshold': 0.7533314824104309, 'british-test_euclidean_f1': 0.8053097345132744, 'british-test_euclidean_f1_threshold': 0.8344411849975586, 'british-test_euclidean_precision': 0.7109375, 'british-test_euclidean_recall': 0.9285714285714286, 'british-test_euclidean_ap': 0.8657974477850441, 'british-test_max_accuracy': 0.7687861271676301, 'british-test_max_accuracy_threshold': 11.92885971069336, 'british-test_max_f1': 0.8071748878923766, 'british-test_max_f1_threshold': 12.846293449401855, 'british-test_max_precision': 0.72, 'british-test_max_recall': 0.9285714285714286, 'british-test_max_ap': 0.8657974477850441}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca9d38527134ef0aea22bc22eae5dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for darkreddit: {'darkreddit-test_cosine_accuracy': 0.6529126213592233, 'darkreddit-test_cosine_accuracy_threshold': 0.8751990795135498, 'darkreddit-test_cosine_f1': 0.6983546617915904, 'darkreddit-test_cosine_f1_threshold': 0.7424333691596985, 'darkreddit-test_cosine_precision': 0.5601173020527859, 'darkreddit-test_cosine_recall': 0.9271844660194175, 'darkreddit-test_cosine_ap': 0.7347184664311759, 'darkreddit-test_dot_accuracy': 0.6529126213592233, 'darkreddit-test_dot_accuracy_threshold': 0.8751991987228394, 'darkreddit-test_dot_f1': 0.6983546617915904, 'darkreddit-test_dot_f1_threshold': 0.7424334287643433, 'darkreddit-test_dot_precision': 0.5601173020527859, 'darkreddit-test_dot_recall': 0.9271844660194175, 'darkreddit-test_dot_ap': 0.7347184664311759, 'darkreddit-test_manhattan_accuracy': 0.6601941747572816, 'darkreddit-test_manhattan_accuracy_threshold': 8.842761993408203, 'darkreddit-test_manhattan_f1': 0.6998087954110899, 'darkreddit-test_manhattan_f1_threshold': 10.681654930114746, 'darkreddit-test_manhattan_precision': 0.5772870662460567, 'darkreddit-test_manhattan_recall': 0.8883495145631068, 'darkreddit-test_manhattan_ap': 0.7357563160360666, 'darkreddit-test_euclidean_accuracy': 0.6529126213592233, 'darkreddit-test_euclidean_accuracy_threshold': 0.4996016025543213, 'darkreddit-test_euclidean_f1': 0.6983546617915904, 'darkreddit-test_euclidean_f1_threshold': 0.7177278399467468, 'darkreddit-test_euclidean_precision': 0.5601173020527859, 'darkreddit-test_euclidean_recall': 0.9271844660194175, 'darkreddit-test_euclidean_ap': 0.7347184664311759, 'darkreddit-test_max_accuracy': 0.6601941747572816, 'darkreddit-test_max_accuracy_threshold': 8.842761993408203, 'darkreddit-test_max_f1': 0.6998087954110899, 'darkreddit-test_max_f1_threshold': 10.681654930114746, 'darkreddit-test_max_precision': 0.5772870662460567, 'darkreddit-test_max_recall': 0.9271844660194175, 'darkreddit-test_max_ap': 0.7357563160360666}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5cacd975d94be9b1c999864ccc99f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for imdb: {'imdb-test_cosine_accuracy': 0.7480636833046471, 'imdb-test_cosine_accuracy_threshold': 0.7538917064666748, 'imdb-test_cosine_f1': 0.7618308766485649, 'imdb-test_cosine_f1_threshold': 0.7126221656799316, 'imdb-test_cosine_precision': 0.6910626319493315, 'imdb-test_cosine_recall': 0.8487467588591184, 'imdb-test_cosine_ap': 0.8109513525642077, 'imdb-test_dot_accuracy': 0.7480636833046471, 'imdb-test_dot_accuracy_threshold': 0.7538917064666748, 'imdb-test_dot_f1': 0.7618308766485649, 'imdb-test_dot_f1_threshold': 0.7126221656799316, 'imdb-test_dot_precision': 0.6910626319493315, 'imdb-test_dot_recall': 0.8487467588591184, 'imdb-test_dot_ap': 0.8109513525642077, 'imdb-test_manhattan_accuracy': 0.7480636833046471, 'imdb-test_manhattan_accuracy_threshold': 10.824899673461914, 'imdb-test_manhattan_f1': 0.7636697247706423, 'imdb-test_manhattan_f1_threshold': 12.343918800354004, 'imdb-test_manhattan_precision': 0.6635841836734694, 'imdb-test_manhattan_recall': 0.8993085566119274, 'imdb-test_manhattan_ap': 0.8104510862612488, 'imdb-test_euclidean_accuracy': 0.7480636833046471, 'imdb-test_euclidean_accuracy_threshold': 0.7015814781188965, 'imdb-test_euclidean_f1': 0.7618308766485649, 'imdb-test_euclidean_f1_threshold': 0.7581263780593872, 'imdb-test_euclidean_precision': 0.6910626319493315, 'imdb-test_euclidean_recall': 0.8487467588591184, 'imdb-test_euclidean_ap': 0.8109513525642077, 'imdb-test_max_accuracy': 0.7480636833046471, 'imdb-test_max_accuracy_threshold': 10.824899673461914, 'imdb-test_max_f1': 0.7636697247706423, 'imdb-test_max_f1_threshold': 12.343918800354004, 'imdb-test_max_precision': 0.6910626319493315, 'imdb-test_max_recall': 0.8993085566119274, 'imdb-test_max_ap': 0.8109513525642077}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5356cf3816541739c535362ee41cd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for pan11: {'pan11-test_cosine_accuracy': 0.6146131805157593, 'pan11-test_cosine_accuracy_threshold': 0.7716286182403564, 'pan11-test_cosine_f1': 0.692144373673036, 'pan11-test_cosine_f1_threshold': 0.6748872995376587, 'pan11-test_cosine_precision': 0.5659722222222222, 'pan11-test_cosine_recall': 0.8907103825136612, 'pan11-test_cosine_ap': 0.6618253164528178, 'pan11-test_dot_accuracy': 0.6146131805157593, 'pan11-test_dot_accuracy_threshold': 0.7716286778450012, 'pan11-test_dot_f1': 0.692144373673036, 'pan11-test_dot_f1_threshold': 0.6748872995376587, 'pan11-test_dot_precision': 0.5659722222222222, 'pan11-test_dot_recall': 0.8907103825136612, 'pan11-test_dot_ap': 0.6618253164528178, 'pan11-test_manhattan_accuracy': 0.6146131805157593, 'pan11-test_manhattan_accuracy_threshold': 10.506285667419434, 'pan11-test_manhattan_f1': 0.692063492063492, 'pan11-test_manhattan_f1_threshold': 12.561086654663086, 'pan11-test_manhattan_precision': 0.5647668393782384, 'pan11-test_manhattan_recall': 0.8934426229508197, 'pan11-test_manhattan_ap': 0.661792576673245, 'pan11-test_euclidean_accuracy': 0.6146131805157593, 'pan11-test_euclidean_accuracy_threshold': 0.6758272647857666, 'pan11-test_euclidean_f1': 0.692144373673036, 'pan11-test_euclidean_f1_threshold': 0.8063653707504272, 'pan11-test_euclidean_precision': 0.5659722222222222, 'pan11-test_euclidean_recall': 0.8907103825136612, 'pan11-test_euclidean_ap': 0.6618253164528178, 'pan11-test_max_accuracy': 0.6146131805157593, 'pan11-test_max_accuracy_threshold': 10.506285667419434, 'pan11-test_max_f1': 0.692144373673036, 'pan11-test_max_f1_threshold': 12.561086654663086, 'pan11-test_max_precision': 0.5659722222222222, 'pan11-test_max_recall': 0.8934426229508197, 'pan11-test_max_ap': 0.6618253164528178}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19163e11aaa74420a97e4b61f1614f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for pan13: {'pan13-test_cosine_accuracy': 0.6111111111111112, 'pan13-test_cosine_accuracy_threshold': 0.9473857283592224, 'pan13-test_cosine_f1': 0.6, 'pan13-test_cosine_f1_threshold': 0.8083878755569458, 'pan13-test_cosine_precision': 0.5, 'pan13-test_cosine_recall': 0.75, 'pan13-test_cosine_ap': 0.5628945707070707, 'pan13-test_dot_accuracy': 0.6111111111111112, 'pan13-test_dot_accuracy_threshold': 0.9473857879638672, 'pan13-test_dot_f1': 0.6, 'pan13-test_dot_f1_threshold': 0.8083878755569458, 'pan13-test_dot_precision': 0.5, 'pan13-test_dot_recall': 0.75, 'pan13-test_dot_ap': 0.5628945707070707, 'pan13-test_manhattan_accuracy': 0.6111111111111112, 'pan13-test_manhattan_accuracy_threshold': 5.042365074157715, 'pan13-test_manhattan_f1': 0.6, 'pan13-test_manhattan_f1_threshold': 9.648418426513672, 'pan13-test_manhattan_precision': 0.5, 'pan13-test_manhattan_recall': 0.75, 'pan13-test_manhattan_ap': 0.5420612373737375, 'pan13-test_euclidean_accuracy': 0.6111111111111112, 'pan13-test_euclidean_accuracy_threshold': 0.32168805599212646, 'pan13-test_euclidean_f1': 0.6, 'pan13-test_euclidean_f1_threshold': 0.6190159320831299, 'pan13-test_euclidean_precision': 0.5, 'pan13-test_euclidean_recall': 0.75, 'pan13-test_euclidean_ap': 0.5628945707070707, 'pan13-test_max_accuracy': 0.6111111111111112, 'pan13-test_max_accuracy_threshold': 5.042365074157715, 'pan13-test_max_f1': 0.6, 'pan13-test_max_f1_threshold': 9.648418426513672, 'pan13-test_max_precision': 0.5, 'pan13-test_max_recall': 0.75, 'pan13-test_max_ap': 0.5628945707070707}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f423b15568c4196bdfc13e64677d68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for pan14: {'pan14-test_cosine_accuracy': 0.625, 'pan14-test_cosine_accuracy_threshold': 0.7652945518493652, 'pan14-test_cosine_f1': 0.7008849557522123, 'pan14-test_cosine_f1_threshold': 0.39485129714012146, 'pan14-test_cosine_precision': 0.5424657534246575, 'pan14-test_cosine_recall': 0.99, 'pan14-test_cosine_ap': 0.5812960852351552, 'pan14-test_dot_accuracy': 0.625, 'pan14-test_dot_accuracy_threshold': 0.76529461145401, 'pan14-test_dot_f1': 0.7008849557522123, 'pan14-test_dot_f1_threshold': 0.39485129714012146, 'pan14-test_dot_precision': 0.5424657534246575, 'pan14-test_dot_recall': 0.99, 'pan14-test_dot_ap': 0.5812960852351552, 'pan14-test_manhattan_accuracy': 0.6225, 'pan14-test_manhattan_accuracy_threshold': 10.523223876953125, 'pan14-test_manhattan_f1': 0.7008849557522123, 'pan14-test_manhattan_f1_threshold': 17.252708435058594, 'pan14-test_manhattan_precision': 0.5424657534246575, 'pan14-test_manhattan_recall': 0.99, 'pan14-test_manhattan_ap': 0.5838004243393022, 'pan14-test_euclidean_accuracy': 0.625, 'pan14-test_euclidean_accuracy_threshold': 0.6851356029510498, 'pan14-test_euclidean_f1': 0.7008849557522123, 'pan14-test_euclidean_f1_threshold': 1.1001348495483398, 'pan14-test_euclidean_precision': 0.5424657534246575, 'pan14-test_euclidean_recall': 0.99, 'pan14-test_euclidean_ap': 0.5812960852351552, 'pan14-test_max_accuracy': 0.625, 'pan14-test_max_accuracy_threshold': 10.523223876953125, 'pan14-test_max_f1': 0.7008849557522123, 'pan14-test_max_f1_threshold': 17.252708435058594, 'pan14-test_max_precision': 0.5424657534246575, 'pan14-test_max_recall': 0.99, 'pan14-test_max_ap': 0.5838004243393022}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdc37d49a0742d9ac493ec4e2e46a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result for pan15: {'pan15-test_cosine_accuracy': 0.6, 'pan15-test_cosine_accuracy_threshold': 0.8211225271224976, 'pan15-test_cosine_f1': 0.695364238410596, 'pan15-test_cosine_f1_threshold': 0.5785237550735474, 'pan15-test_cosine_precision': 0.5357142857142857, 'pan15-test_cosine_recall': 0.9905660377358491, 'pan15-test_cosine_ap': 0.5971832064782955, 'pan15-test_dot_accuracy': 0.6, 'pan15-test_dot_accuracy_threshold': 0.8211225271224976, 'pan15-test_dot_f1': 0.695364238410596, 'pan15-test_dot_f1_threshold': 0.5785236358642578, 'pan15-test_dot_precision': 0.5357142857142857, 'pan15-test_dot_recall': 0.9905660377358491, 'pan15-test_dot_ap': 0.5971832064782955, 'pan15-test_manhattan_accuracy': 0.59, 'pan15-test_manhattan_accuracy_threshold': 9.681791305541992, 'pan15-test_manhattan_f1': 0.6976744186046512, 'pan15-test_manhattan_f1_threshold': 14.060454368591309, 'pan15-test_manhattan_precision': 0.5384615384615384, 'pan15-test_manhattan_recall': 0.9905660377358491, 'pan15-test_manhattan_ap': 0.5930093533984109, 'pan15-test_euclidean_accuracy': 0.6, 'pan15-test_euclidean_accuracy_threshold': 0.5981258153915405, 'pan15-test_euclidean_f1': 0.695364238410596, 'pan15-test_euclidean_f1_threshold': 0.9180703163146973, 'pan15-test_euclidean_precision': 0.5357142857142857, 'pan15-test_euclidean_recall': 0.9905660377358491, 'pan15-test_euclidean_ap': 0.5971832064782955, 'pan15-test_max_accuracy': 0.6, 'pan15-test_max_accuracy_threshold': 9.681791305541992, 'pan15-test_max_f1': 0.6976744186046512, 'pan15-test_max_f1_threshold': 14.060454368591309, 'pan15-test_max_precision': 0.5384615384615384, 'pan15-test_max_recall': 0.9905660377358491, 'pan15-test_max_ap': 0.5971832064782955}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4926b547fb404388f39c4d6ac916c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/755 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, test_dataset \u001b[38;5;129;01min\u001b[39;00m test_datasets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     test_evaluator \u001b[38;5;241m=\u001b[39m BinaryClassificationEvaluator(\n\u001b[1;32m      3\u001b[0m         sentences1\u001b[38;5;241m=\u001b[39mtest_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m         sentences2\u001b[38;5;241m=\u001b[39mtest_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext2\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m----> 9\u001b[0m     evaluation_result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation result for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluation_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/evaluation/BinaryClassificationEvaluator.py:181\u001b[0m, in \u001b[0;36mBinaryClassificationEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m    177\u001b[0m     out_txt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (truncated to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary Accuracy Evaluation of the model on the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_txt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m file_output_data \u001b[38;5;241m=\u001b[39m [epoch, steps]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m header_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcsv_headers:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/evaluation/BinaryClassificationEvaluator.py:231\u001b[0m, in \u001b[0;36mBinaryClassificationEvaluator.compute_metrices\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    229\u001b[0m     embeddings2 \u001b[38;5;241m=\u001b[39m embeddings[\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences1) :]\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     emb_dict \u001b[38;5;241m=\u001b[39m {sent: emb \u001b[38;5;28;01mfor\u001b[39;00m sent, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sentences, embeddings)}\n\u001b[1;32m    238\u001b[0m     embeddings1 \u001b[38;5;241m=\u001b[39m [emb_dict[sent] \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences1]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py:485\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    484\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentences_sorted[start_index : start_index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m--> 485\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    487\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py:922\u001b[0m, in \u001b[0;36mSentenceTransformer.tokenize\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: Union[List[\u001b[38;5;28mstr\u001b[39m], List[Dict], List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[1;32m    912\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;03m    Tokenizes the texts.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;124;03m            \"attention_mask\", and \"token_type_ids\".\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py:166\u001b[0m, in \u001b[0;36mTransformer.tokenize\u001b[0;34m(self, texts, padding)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case:\n\u001b[1;32m    163\u001b[0m     to_tokenize \u001b[38;5;241m=\u001b[39m [[s\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m to_tokenize]\n\u001b[1;32m    165\u001b[0m output\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mto_tokenize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongest_first\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2883\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2881\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2882\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2883\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2885\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2969\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2964\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2965\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2966\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2967\u001b[0m         )\n\u001b[1;32m   2968\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2990\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2991\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3007\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3008\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3160\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3152\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3153\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3158\u001b[0m )\n\u001b[0;32m-> 3160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py:511\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    504\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m    505\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    509\u001b[0m )\n\u001b[0;32m--> 511\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    523\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    525\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    535\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for name, test_dataset in test_datasets.items():\n",
    "    test_evaluator = BinaryClassificationEvaluator(\n",
    "        sentences1=test_dataset[\"text1\"],\n",
    "        sentences2=test_dataset[\"text2\"],\n",
    "        labels=test_dataset[\"score\"],\n",
    "        name=f\"{name}-test\",\n",
    "        show_progress_bar=True,\n",
    "    )\n",
    "    evaluation_result = test_evaluator(model)\n",
    "    print(f\"Evaluation result for {name}: {evaluation_result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
