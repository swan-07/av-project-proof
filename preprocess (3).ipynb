{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cd0afc-caba-4b42-8b68-a75ea547a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('/workspace/train.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "222480e4-12b6-4700-86a8-2737e064a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/workspace/val.pkl', 'rb') as f:\n",
    "#     val_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd45bdb0-b5ee-452c-b033-e93ed3bb9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/workspace/test.pkl', 'rb') as f:\n",
    "#     test_dfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7945b4-a3e7-4612-98a1-8322bbb55be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arxiv': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 106\n",
       " }),\n",
       " 'blogs': Dataset({\n",
       "     features: ['text1', 'text2', 'score'],\n",
       "     num_rows: 8840\n",
       " })}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from itertools import islice\n",
    "# dict(islice(test_dfs.items(), 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ea9d9-da88-4aca-a28b-b5c02b2216d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textcomplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de25ed0-d13b-4f63-910f-4ecedfbd5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ed0873-c50c-4a24-a136-7fed92b34fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c64e2a5-9859-4352-9b3d-167a109e943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import glob\n",
    "from tqdm.auto import trange, tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "from features import prepare_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb70987e-87c8-4d63-b847-9783e8c44083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ed3ccd3-fccc-4957-bf01-13f5d8e1768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval = val_df['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0cde2ae-772f-498b-987b-f8de9d07d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small = {\n",
    "#     'text1': ['example text1'] ,  # Sample train texts\n",
    "#     'text2': ['example text2'] ,  # Sample train texts\n",
    "#     'same': [1]     # Sample train labels\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ab9e6d-123f-4dfd-872c-ea1cab7d278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    examples['text1'] = [prepare_entry(text, mode='accurate', tokenizer='casual') for text in tqdm(examples['text1'], desc='Processing text1')]\n",
    "    examples['text2'] = [prepare_entry(text, mode='accurate', tokenizer='casual') for text in tqdm(examples['text2'], desc='Processing text2')]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56706e51-60cb-4c74-be1c-0222f9421051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset, DatasetDict\n",
    "# small = Dataset.from_dict(small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8470da7-4ccb-4e7f-90fd-13cf77ae3d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pos_tag_chunk_subtrees': ['NP[NN NN CD]'],\n",
       "  'pos_tag_chunks': ['NP'],\n",
       "  'pos_tags': ['NN', 'NN', 'CD'],\n",
       "  'preprocessed': 'example text1',\n",
       "  'tokens': ['example', 'text', '1']}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# small['text1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "260e99a7-952e-4087-a2b2-a16d8e2578ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1843f4f8c3174231a73ad59a0070d4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc9fb5e43b3428eb213d4e6e05417ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing text1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259424e4a73940179998b632e74d5d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing text2:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# small = small.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e657585-2090-4a13-b3a6-c035daeeb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_into_chunks(dataset, num_chunks):\n",
    "    chunk_size = len(dataset['text1']) // num_chunks\n",
    "    chunks = []\n",
    "    for i in range(num_chunks):\n",
    "        chunk = {\n",
    "            'text1': dataset['text1'][i * chunk_size:(i + 1) * chunk_size],\n",
    "            'text2': dataset['text2'][i * chunk_size:(i + 1) * chunk_size],\n",
    "            'score': dataset['score'][i * chunk_size:(i + 1) * chunk_size]\n",
    "        }\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6e85780-7f62-4f0e-9d46-a9d5cf997d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_chunks = split_into_chunks(train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "617e3d5a-6cbe-4177-bced-4eb0fba10f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('trainchunk0.pkl', 'wb') as f:\n",
    "#     pickle.dump(processed_chunk_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf4d2a24-e610-4be8-a9de-32d939985def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('trainchunk1.pkl', 'wb') as f:\n",
    "#     pickle.dump(processed_chunk_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c19112ca-3b8f-4cb2-bda7-e4290e939bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('trainchunk2.pkl', 'wb') as f:\n",
    "#     pickle.dump(processed_chunk_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f821559b-5a84-4d59-b44d-f0eca1a9f93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaee39de1ca0402d85f5d0666b0bd8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing text1:   0%|          | 0/32528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c0322000a44ff8b30487eab88dece3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing text2:   0%|          | 0/32528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# processed_chunk_4 = preprocess_function(train_chunks[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b48612cc-a7ca-4e4b-8074-2db838f63cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainchunk3.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_chunk_4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303dcf7-46dd-440c-b7d5-22b9006510c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b99309cbdb425aba006a1c4a100b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing text1:   0%|          | 0/32528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222640f22abb48eabd22e546ed0f8ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing text2:   0%|          | 0/32528 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_chunk_5 = preprocess_function(train_chunks[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc28fe-9365-456a-a646-e727185ef7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainchunk4.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_chunk_5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d62a98-564e-4e90-8507-2141ab8eee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_chunk_10 = preprocess_function(train_chunks[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cad58-1c38-4fc0-8d47-116fd90294ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainchunk9.pkl', 'wb') as f:\n",
    "    pickle.dump(processed_chunk_10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafb4602-ceff-49bd-b878-00ea92a9792c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_chunk_5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mprocessed_chunk_5\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_chunk_5' is not defined"
     ]
    }
   ],
   "source": [
    "len(processed_chunk_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1faa759-60eb-4d9a-9406-8ac8a922e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombine the processed chunks into one dataset\n",
    "def combine_chunks(chunks):\n",
    "    combined = {'text1': [], 'text2': [], 'score': []}\n",
    "    for chunk in chunks:\n",
    "        combined['text1'].extend(chunk['text1'])\n",
    "        combined['text2'].extend(chunk['text2'])\n",
    "        combined['score'].extend(chunk['score'])\n",
    "    return combined\n",
    "\n",
    "processed_chunks = [\n",
    "    processed_chunk_1,\n",
    "    processed_chunk_2,\n",
    "    processed_chunk_3,\n",
    "    processed_chunk_4,\n",
    "    processed_chunk_5,\n",
    "    processed_chunk_6,\n",
    "    processed_chunk_7,\n",
    "    processed_chunk_8,\n",
    "    processed_chunk_9,\n",
    "    processed_chunk_10\n",
    "]\n",
    "\n",
    "processed_train = combine_chunks(processed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0eaf77-c70c-4a3e-99ac-7ea7a93ec33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('trainchunk0.pkl', 'rb') as f:\n",
    "    trainchunk0 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1138e87-baf4-448d-a277-f93c9244d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('trainchunk1.pkl', 'rb') as f:\n",
    "    trainchunk1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f31ecf1-167d-4308-afd0-4cb8a4b88bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('trainchunk2.pkl', 'rb') as f:\n",
    "    trainchunk2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c471f-46c9-4ad8-8185-2f5860a12e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('trainchunk3.pkl', 'rb') as f:\n",
    "    trainchunk3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4e251-790d-4eb0-9847-d6f46178cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('trainchunk8.pkl', 'rb') as f:\n",
    "    trainchunk8 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95d975-044f-4973-a9f2-0d5006ad1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recombine the processed chunks into one dataset\n",
    "def combine_chunks(chunks):\n",
    "    combined = {'text1': [], 'text2': [], 'score': []}\n",
    "    for chunk in chunks:\n",
    "        combined['text1'].extend(chunk['text1'])\n",
    "        combined['text2'].extend(chunk['text2'])\n",
    "        combined['score'].extend(chunk['score'])\n",
    "    return combined\n",
    "\n",
    "processed_chunks = [\n",
    "    trainchunk0,\n",
    "    trainchunk1,\n",
    "    trainchunk2,\n",
    "    trainchunk3,\n",
    "    trainchunk8\n",
    "]\n",
    "\n",
    "processed_train = combine_chunks(processed_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
